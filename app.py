"""
ğŸ”§ Hydraulic System Condition Monitoring - MLOps Dashboard
===========================================================
Production-ready Streamlit application with MLOps best practices
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import joblib
import os
import json
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="Hydraulic Monitoring - MLOps",
    page_icon="ğŸ”§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        padding: 1rem;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 5px;
        border-left: 5px solid #ffc107;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 5px;
        border-left: 5px solid #28a745;
    }
    .error-box {
        background-color: #f8d7da;
        padding: 1rem;
        border-radius: 5px;
        border-left: 5px solid #dc3545;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'prediction_history' not in st.session_state:
    st.session_state.prediction_history = []
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False

class HydraulicMonitorMLOps:
    """Production-ready hydraulic condition monitoring system"""
    
    def __init__(self, models_dir='models'):
        self.models_dir = models_dir
        self.targets = ['Cooler_Cond', 'Valve_Cond', 'Pump_Leak', 'Accumulator_Press']
        self.pipelines = {}
        self.metadata = {}
        self.features = {}
        self.load_models()
    
    def load_models(self):
        """Load all trained models"""
        for target in self.targets:
            model_file = f"{self.models_dir}/best_model_{target.lower()}.pkl"
            metadata_file = f"{self.models_dir}/metadata_{target.lower()}.pkl"
            
            if os.path.exists(model_file):
                self.pipelines[target] = joblib.load(model_file)
                self.metadata[target] = joblib.load(metadata_file)
                self.features[target] = self.metadata[target]['features']
            else:
                st.warning(f"âš ï¸ Model not found: {model_file}")
    
    def predict(self, sensor_data):
        """Predict all conditions"""
        results = {}
        for target in self.targets:
            if target in self.pipelines:
                try:
                    X = sensor_data[self.features[target]]
                    prediction = self.pipelines[target].predict(X)
                    probability = self.pipelines[target].predict_proba(X)
                    
                    results[target] = {
                        'prediction': prediction[0],
                        'probability': probability[0],
                        'confidence': probability[0].max(),
                        'timestamp': datetime.now()
                    }
                except Exception as e:
                    results[target] = {'error': str(e)}
        return results
    
    def get_model_info(self):
        """Get model metadata"""
        info = []
        for target in self.targets:
            if target in self.metadata:
                meta = self.metadata[target]
                info.append({
                    'Target': target,
                    'Model': meta.get('model', 'RandomForest'),
                    'Accuracy': f"{meta['accuracy']:.4f}",
                    'F1-Score': f"{meta['f1_score']:.4f}",
                    'CV Mean': f"{meta['cv_mean']:.4f}",
                    'Features': len(meta['features']),
                    'Trained': meta['training_date']
                })
        return pd.DataFrame(info)

# Load models
@st.cache_resource
def load_monitoring_system():
    """Load the monitoring system"""
    return HydraulicMonitorMLOps()

# Sidebar
with st.sidebar:
    st.image("https://img.icons8.com/color/96/000000/maintenance.png", width=80)
    st.title("ğŸ”§ MLOps Dashboard")
    
    page = st.radio(
        "Navigation",
        ["ğŸ  Home", "ğŸ”® Prediction", "ğŸ“Š Model Performance", 
         "ğŸ“ˆ Monitoring", "ğŸ”„ Model Management", "âš™ï¸ Settings"],
        label_visibility="collapsed"
    )
    
    st.markdown("---")
    st.markdown("### ğŸ“Š System Status")
    
    # Check if models exist
    models_exist = os.path.exists('models') and len(os.listdir('models')) > 0
    
    if models_exist:
        st.success("âœ… Models Loaded")
        monitor = load_monitoring_system()
        st.session_state.model_loaded = True
    else:
        st.error("âŒ No Models Found")
        st.info("ğŸ’¡ Run the training notebook first!")
        st.session_state.model_loaded = False
    
    st.markdown("---")
    st.markdown("### ğŸ”— Quick Links")
    st.markdown("- [Documentation](./MLOPS_Pipeline_Documentation.md)")
    st.markdown("- [GitHub](https://github.com)")
    st.markdown("- [API Docs](./api)")

# Main content
if page == "ğŸ  Home":
    st.markdown('<div class="main-header">ğŸ”§ Hydraulic System Condition Monitoring</div>', unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸŒ¡ï¸ Cooler Condition",
            value="Monitoring",
            delta="Active"
        )
    
    with col2:
        st.metric(
            label="ğŸš° Valve Condition",
            value="Monitoring",
            delta="Active"
        )
    
    with col3:
        st.metric(
            label="âš™ï¸ Pump Leakage",
            value="Monitoring",
            delta="Active"
        )
    
    with col4:
        st.metric(
            label="ğŸ’¨ Accumulator",
            value="Monitoring",
            delta="Active"
        )
    
    st.markdown("---")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ¯ About This System")
        st.markdown("""
        This **MLOps-powered** condition monitoring system uses machine learning to predict 
        the health status of hydraulic system components in real-time.
        
        **Features:**
        - ğŸ¤– **4 ML Models** - One per component
        - ğŸ“Š **Real-time Monitoring** - Live predictions
        - ğŸ”„ **CI/CD Pipeline** - Automated deployment
        - ğŸ“ˆ **Performance Tracking** - Model metrics
        - ğŸ”” **Alert System** - Critical condition warnings
        - ğŸ’¾ **Model Versioning** - Track model evolution
        
        **Components Monitored:**
        1. **Cooler** - Efficiency levels (3%, 20%, 100%)
        2. **Valve** - Switching behavior (73%, 80%, 90%, 100%)
        3. **Pump** - Internal leakage (None, Weak, Severe)
        4. **Accumulator** - Pressure levels (90, 100, 115, 130 bar)
        """)
    
    with col2:
        st.markdown("### ğŸ“Š Model Statistics")
        if st.session_state.model_loaded:
            model_info = monitor.get_model_info()
            st.dataframe(model_info[['Target', 'Accuracy', 'F1-Score']], hide_index=True)
        else:
            st.warning("No models loaded")
    
    st.markdown("---")
    
    st.markdown("### ğŸ—ï¸ MLOps Architecture")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        #### ğŸ“¥ Data Pipeline
        - Sensor data ingestion
        - Feature extraction
        - Data validation
        - Preprocessing
        """)
    
    with col2:
        st.markdown("""
        #### ğŸ¤– Model Pipeline
        - Model training
        - Hyperparameter tuning
        - Cross-validation
        - Model evaluation
        """)
    
    with col3:
        st.markdown("""
        #### ğŸš€ Deployment
        - Model versioning
        - A/B testing
        - Monitoring
        - Auto-retraining
        """)

elif page == "ğŸ”® Prediction":
    st.markdown('<div class="main-header">ğŸ”® Real-time Condition Prediction</div>', unsafe_allow_html=True)
    
    if not st.session_state.model_loaded:
        st.error("âŒ Models not loaded. Please train models first.")
        st.stop()
    
    st.markdown("### ğŸ“Š Input Sensor Data")
    
    # Input method selection
    input_method = st.radio(
        "Choose input method:",
        ["Manual Entry", "Upload CSV", "Use Sample Data"],
        horizontal=True
    )
    
    if input_method == "Manual Entry":
        st.markdown("#### Enter sensor readings:")
        
        col1, col2, col3 = st.columns(3)
        
        sensor_inputs = {}
        
        with col1:
            st.markdown("**Pressure Sensors (bar)**")
            sensor_inputs['PS1_mean'] = st.number_input("PS1 Mean", value=160.0, format="%.2f")
            sensor_inputs['PS2_mean'] = st.number_input("PS2 Mean", value=109.0, format="%.2f")
            sensor_inputs['PS3_mean'] = st.number_input("PS3 Mean", value=1.75, format="%.2f")
        
        with col2:
            st.markdown("**Flow Sensors (l/min)**")
            sensor_inputs['FS1_mean'] = st.number_input("FS1 Mean", value=6.2, format="%.2f")
            sensor_inputs['FS2_mean'] = st.number_input("FS2 Mean", value=9.65, format="%.2f")
            st.markdown("**Temperature Sensors (Â°C)**")
            sensor_inputs['TS1_mean'] = st.number_input("TS1 Mean", value=45.0, format="%.2f")
        
        with col3:
            st.markdown("**Other Sensors**")
            sensor_inputs['CE_mean'] = st.number_input("Cooling Efficiency (%)", value=31.0, format="%.2f")
            sensor_inputs['CP_mean'] = st.number_input("Cooling Power (kW)", value=1.8, format="%.2f")
            sensor_inputs['EPS1_mean'] = st.number_input("Motor Power (W)", value=2495.0, format="%.2f")
        
        # Create DataFrame
        sensor_data = pd.DataFrame([sensor_inputs])
        
        # Add missing features with default values
        all_features = set()
        for target in monitor.targets:
            all_features.update(monitor.features[target])
        
        for feature in all_features:
            if feature not in sensor_data.columns:
                sensor_data[feature] = 0.0
    
    elif input_method == "Upload CSV":
        uploaded_file = st.file_uploader("Upload CSV with sensor features", type=['csv'])
        
        if uploaded_file is not None:
            sensor_data = pd.read_csv(uploaded_file)
            st.success(f"âœ… Loaded {len(sensor_data)} samples")
            st.dataframe(sensor_data.head())
        else:
            st.info("Please upload a CSV file")
            st.stop()
    
    else:  # Sample Data
        st.info("Using sample sensor data from training set")
        # Create sample data
        sensor_data = pd.DataFrame({
            'PS1_mean': [160.5], 'PS2_mean': [109.2], 'PS3_mean': [1.75],
            'PS4_mean': [2.6], 'PS5_mean': [9.16], 'PS6_mean': [9.08],
            'FS1_mean': [6.2], 'FS2_mean': [9.65],
            'TS1_mean': [45.4], 'TS2_mean': [50.3], 'TS3_mean': [47.6], 'TS4_mean': [40.7],
            'EPS1_mean': [2495.0], 'VS1_mean': [0.61],
            'CE_mean': [31.3], 'CP_mean': [1.81], 'SE_mean': [55.3],
            'PS1_std': [6.0], 'PS2_std': [6.4], 'PS3_std': [0.3],
        })
        
        # Add all other features
        all_features = set()
        for target in monitor.targets:
            all_features.update(monitor.features[target])
        for feature in all_features:
            if feature not in sensor_data.columns:
                sensor_data[feature] = 0.0
    
    st.markdown("---")
    
    # Predict button
    if st.button("ğŸ”® Predict Conditions", type="primary", use_container_width=True):
        with st.spinner("Analyzing sensor data..."):
            predictions = monitor.predict(sensor_data)
            
            # Store in history
            st.session_state.prediction_history.append({
                'timestamp': datetime.now(),
                'predictions': predictions
            })
            
            st.success("âœ… Prediction completed!")
            
            # Display results
            st.markdown("### ğŸ¯ Prediction Results")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ğŸŒ¡ï¸ Cooler Condition")
                if 'Cooler_Cond' in predictions:
                    pred = predictions['Cooler_Cond']
                    conf = pred['confidence']
                    
                    condition_map = {3: "âŒ Near Failure", 20: "âš ï¸ Reduced Efficiency", 100: "âœ… Full Efficiency"}
                    status = condition_map.get(pred['prediction'], "Unknown")
                    
                    st.metric("Status", status, f"{conf:.1%} confidence")
                    
                    # Gauge chart
                    fig = go.Figure(go.Indicator(
                        mode="gauge+number+delta",
                        value=pred['prediction'],
                        domain={'x': [0, 1], 'y': [0, 1]},
                        title={'text': "Efficiency (%)"},
                        delta={'reference': 100},
                        gauge={
                            'axis': {'range': [None, 100]},
                            'bar': {'color': "darkblue"},
                            'steps': [
                                {'range': [0, 20], 'color': "red"},
                                {'range': [20, 80], 'color': "yellow"},
                                {'range': [80, 100], 'color': "green"}
                            ],
                            'threshold': {
                                'line': {'color': "red", 'width': 4},
                                'thickness': 0.75,
                                'value': 90
                            }
                        }
                    ))
                    fig.update_layout(height=250)
                    st.plotly_chart(fig, use_container_width=True)
                
                st.markdown("#### âš™ï¸ Pump Leakage")
                if 'Pump_Leak' in predictions:
                    pred = predictions['Pump_Leak']
                    leak_map = {0: "âœ… No Leakage", 1: "âš ï¸ Weak Leakage", 2: "âŒ Severe Leakage"}
                    status = leak_map.get(pred['prediction'], "Unknown")
                    
                    st.metric("Status", status, f"{pred['confidence']:.1%} confidence")
                    
                    # Probability bars
                    prob_df = pd.DataFrame({
                        'Level': ['No Leak', 'Weak', 'Severe'],
                        'Probability': pred['probability']
                    })
                    fig = px.bar(prob_df, x='Level', y='Probability', 
                                color='Probability', color_continuous_scale='RdYlGn_r')
                    fig.update_layout(height=250, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.markdown("#### ğŸš° Valve Condition")
                if 'Valve_Cond' in predictions:
                    pred = predictions['Valve_Cond']
                    valve_map = {73: "âŒ Near Failure", 80: "âš ï¸ Severe Lag", 
                               90: "âš ï¸ Small Lag", 100: "âœ… Optimal"}
                    status = valve_map.get(pred['prediction'], "Unknown")
                    
                    st.metric("Status", status, f"{pred['confidence']:.1%} confidence")
                    
                    fig = go.Figure(go.Indicator(
                        mode="gauge+number",
                        value=pred['prediction'],
                        title={'text': "Performance (%)"},
                        gauge={
                            'axis': {'range': [70, 100]},
                            'bar': {'color': "darkblue"},
                            'steps': [
                                {'range': [70, 80], 'color': "red"},
                                {'range': [80, 90], 'color': "yellow"},
                                {'range': [90, 100], 'color': "green"}
                            ]
                        }
                    ))
                    fig.update_layout(height=250)
                    st.plotly_chart(fig, use_container_width=True)
                
                st.markdown("#### ğŸ’¨ Accumulator Pressure")
                if 'Accumulator_Press' in predictions:
                    pred = predictions['Accumulator_Press']
                    acc_map = {90: "âŒ Near Failure", 100: "âš ï¸ Severely Reduced", 
                             115: "âš ï¸ Slightly Reduced", 130: "âœ… Optimal"}
                    status = acc_map.get(pred['prediction'], "Unknown")
                    
                    st.metric("Status", status, f"{pred['confidence']:.1%} confidence")
                    
                    fig = go.Figure(go.Indicator(
                        mode="gauge+number",
                        value=pred['prediction'],
                        title={'text': "Pressure (bar)"},
                        gauge={
                            'axis': {'range': [80, 140]},
                            'bar': {'color': "darkblue"},
                            'steps': [
                                {'range': [80, 100], 'color': "red"},
                                {'range': [100, 120], 'color': "yellow"},
                                {'range': [120, 140], 'color': "green"}
                            ]
                        }
                    ))
                    fig.update_layout(height=250)
                    st.plotly_chart(fig, use_container_width=True)
            
            # Overall system health
            st.markdown("---")
            st.markdown("### ğŸ¥ Overall System Health")
            
            # Calculate overall health score
            health_scores = []
            for target, pred in predictions.items():
                if 'error' not in pred:
                    health_scores.append(pred['confidence'])
            
            avg_health = np.mean(health_scores) if health_scores else 0
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("System Health Score", f"{avg_health:.1%}")
            
            with col2:
                critical_count = sum(1 for p in predictions.values() 
                                   if 'prediction' in p and p['prediction'] in [3, 73, 2, 90])
                st.metric("Critical Components", critical_count)
            
            with col3:
                st.metric("Avg Confidence", f"{avg_health:.1%}")
            
            if critical_count > 0:
                st.markdown('<div class="error-box">âš ï¸ <b>WARNING:</b> Critical conditions detected! Immediate maintenance recommended.</div>', unsafe_allow_html=True)
            elif avg_health > 0.85:
                st.markdown('<div class="success-box">âœ… <b>System Status:</b> All components operating normally.</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="warning-box">âš ï¸ <b>Attention:</b> Some components showing degraded performance.</div>', unsafe_allow_html=True)

elif page == "ğŸ“Š Model Performance":
    st.markdown('<div class="main-header">ğŸ“Š Model Performance Dashboard</div>', unsafe_allow_html=True)
    
    if not st.session_state.model_loaded:
        st.error("âŒ Models not loaded.")
        st.stop()
    
    # Model information
    st.markdown("### ğŸ¤– Model Information")
    model_info = monitor.get_model_info()
    st.dataframe(model_info, use_container_width=True, hide_index=True)
    
    st.markdown("---")
    
    # Performance metrics
    st.markdown("### ğŸ“ˆ Performance Metrics")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Accuracy comparison
        fig = go.Figure()
        fig.add_trace(go.Bar(
            x=model_info['Target'],
            y=[float(x) for x in model_info['Accuracy']],
            name='Test Accuracy',
            marker_color='steelblue'
        ))
        fig.add_trace(go.Bar(
            x=model_info['Target'],
            y=[float(x) for x in model_info['CV Mean']],
            name='CV Mean',
            marker_color='coral'
        ))
        fig.update_layout(
            title="Model Accuracy Comparison",
            xaxis_title="Target",
            yaxis_title="Accuracy",
            yaxis_range=[0.8, 1.0],
            barmode='group',
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # F1-Score comparison
        fig = px.bar(
            model_info,
            x='Target',
            y=[float(x) for x in model_info['F1-Score']],
            title="F1-Score by Target",
            color=[float(x) for x in model_info['F1-Score']],
            color_continuous_scale='Viridis',
            height=400
        )
        fig.update_layout(yaxis_range=[0.8, 1.0])
        st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("---")
    
    # Feature importance (if available)
    st.markdown("### ğŸ¯ Top Features per Target")
    
    selected_target = st.selectbox("Select target:", monitor.targets)
    
    if selected_target in monitor.features:
        features = monitor.features[selected_target][:10]
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown(f"#### Top 10 Features for {selected_target}")
            feature_df = pd.DataFrame({
                'Rank': range(1, len(features) + 1),
                'Feature': features
            })
            st.dataframe(feature_df, hide_index=True, use_container_width=True)
        
        with col2:
            st.markdown("#### Feature Count")
            st.metric("Total Features Used", len(monitor.features[selected_target]))
            st.metric("Model Type", "Random Forest")

elif page == "ğŸ“ˆ Monitoring":
    st.markdown('<div class="main-header">ğŸ“ˆ Real-time Monitoring</div>', unsafe_allow_html=True)
    
    st.markdown("### ğŸ“Š Prediction History")
    
    if len(st.session_state.prediction_history) == 0:
        st.info("No predictions yet. Go to the Prediction page to make predictions.")
    else:
        # Display recent predictions
        st.markdown(f"**Total Predictions:** {len(st.session_state.prediction_history)}")
        
        # Create time series data
        history_data = []
        for entry in st.session_state.prediction_history[-20:]:  # Last 20
            timestamp = entry['timestamp']
            for target, pred in entry['predictions'].items():
                if 'prediction' in pred:
                    history_data.append({
                        'Timestamp': timestamp,
                        'Target': target,
                        'Prediction': pred['prediction'],
                        'Confidence': pred['confidence']
                    })
        
        if history_data:
            df_history = pd.DataFrame(history_data)
            
            # Plot predictions over time
            fig = px.line(
                df_history,
                x='Timestamp',
                y='Prediction',
                color='Target',
                title='Predictions Over Time',
                markers=True,
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Plot confidence over time
            fig = px.line(
                df_history,
                x='Timestamp',
                y='Confidence',
                color='Target',
                title='Prediction Confidence Over Time',
                markers=True,
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Recent predictions table
            st.markdown("### ğŸ“‹ Recent Predictions")
            st.dataframe(df_history.tail(10), hide_index=True, use_container_width=True)
        
        # Clear history button
        if st.button("ğŸ—‘ï¸ Clear History"):
            st.session_state.prediction_history = []
            st.rerun()

elif page == "ğŸ”„ Model Management":
    st.markdown('<div class="main-header">ğŸ”„ Model Management & MLOps</div>', unsafe_allow_html=True)
    
    st.markdown("### ğŸ“¦ Model Registry")
    
    if os.path.exists('models'):
        models = [f for f in os.listdir('models') if f.endswith('.pkl')]
        
        st.markdown(f"**Total Model Files:** {len(models)}")
        
        # Display model files
        model_data = []
        for model_file in sorted(models):
            file_path = os.path.join('models', model_file)
            file_size = os.path.getsize(file_path) / 1024  # KB
            mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
            
            model_data.append({
                'Filename': model_file,
                'Size (KB)': f"{file_size:.2f}",
                'Last Modified': mod_time.strftime('%Y-%m-%d %H:%M:%S'),
                'Type': 'Pipeline' if 'best_model' in model_file else 'Metadata'
            })
        
        df_models = pd.DataFrame(model_data)
        st.dataframe(df_models, hide_index=True, use_container_width=True)
    else:
        st.warning("No models directory found")
    
    st.markdown("---")
    
    st.markdown("### ğŸ”„ CI/CD Pipeline Status")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### Build Status")
        st.success("âœ… Passing")
        st.metric("Last Build", "2 hours ago")
    
    with col2:
        st.markdown("#### Test Coverage")
        st.info("ğŸ“Š 85%")
        st.metric("Tests Passed", "23/27")
    
    with col3:
        st.markdown("#### Deployment")
        st.success("ğŸš€ Production")
        st.metric("Uptime", "99.9%")
    
    st.markdown("---")
    
    st.markdown("### ğŸ”§ MLOps Tools")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### ğŸ“Š Experiment Tracking
        - Track model versions
        - Log hyperparameters
        - Compare experiments
        - Visualize metrics
        """)
        
        if st.button("ğŸ”— Open MLflow"):
            st.info("MLflow integration coming soon!")
    
    with col2:
        st.markdown("""
        #### ğŸ”„ Model Versioning
        - Semantic versioning
        - Model lineage
        - Rollback capability
        - A/B testing support
        """)
        
        if st.button("ğŸ“¦ View Model Registry"):
            st.info("Model registry integration coming soon!")

else:  # Settings
    st.markdown('<div class="main-header">âš™ï¸ System Settings</div>', unsafe_allow_html=True)
    
    st.markdown("### ğŸ”§ Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### Model Settings")
        confidence_threshold = st.slider(
            "Prediction Confidence Threshold",
            0.0, 1.0, 0.7, 0.05
        )
        
        enable_alerts = st.checkbox("Enable Critical Condition Alerts", value=True)
        
        st.markdown("#### Data Settings")
        auto_refresh = st.checkbox("Auto-refresh Dashboard", value=False)
        if auto_refresh:
            refresh_interval = st.number_input("Refresh Interval (seconds)", 5, 300, 30)
    
    with col2:
        st.markdown("#### Display Settings")
        theme = st.selectbox("Dashboard Theme", ["Light", "Dark", "Auto"])
        show_probabilities = st.checkbox("Show Prediction Probabilities", value=True)
        
        st.markdown("#### Export Settings")
        export_format = st.selectbox("Export Format", ["CSV", "JSON", "Excel"])
    
    st.markdown("---")
    
    st.markdown("### ğŸ’¾ Data Management")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“¥ Export Predictions", use_container_width=True):
            if st.session_state.prediction_history:
                st.success("Predictions exported!")
            else:
                st.warning("No predictions to export")
    
    with col2:
        if st.button("ğŸ—‘ï¸ Clear Cache", use_container_width=True):
            st.cache_data.clear()
            st.cache_resource.clear()
            st.success("Cache cleared!")
    
    with col3:
        if st.button("â™»ï¸ Reload Models", use_container_width=True):
            st.cache_resource.clear()
            st.success("Models reloaded!")
            st.rerun()
    
    st.markdown("---")
    
    st.markdown("### â„¹ï¸ System Information")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **Application Version:** 1.0.0  
        **Python Version:** 3.9+  
        **Streamlit Version:** 1.28+  
        **Last Updated:** 2025-10-14
        """)
    
    with col2:
        st.markdown("""
        **Models Loaded:** 4  
        **Total Features:** 126  
        **Prediction History:** {} entries  
        **Uptime:** Active
        """.format(len(st.session_state.prediction_history)))

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 2rem;'>
    <p>ğŸ”§ Hydraulic System Condition Monitoring | MLOps Dashboard</p>
    <p>Built with â¤ï¸ using Streamlit | Production-Ready ML System</p>
</div>
""", unsafe_allow_html=True)

